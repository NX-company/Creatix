import type { AppMode, DocType, UploadedImage } from '../store'
import { generateContent, generateContentWithImages, generateHTML } from '../api'
import { generateHTMLWithGPT4o } from '../api-openai'
import { generateImagesForDocument, generateImagesFromPlan, replaceImagePlaceholders, type GeneratedImage } from './imageAgent'
import { MODE_CONFIG } from '../config/modes'
import { analyzeContentForImages, type ContentAnalysisResult } from './contentAnalyzer'
import { reviewDocument, buildFeedbackForAgents, type QAReport } from './qaAgent'
import { AGENT_MODELS, QA_CONFIG } from '../config/agents'

export type GenerationResult = {
  html: string
  content: string
  generatedImages: GeneratedImage[]
  mode: AppMode
  qaReport?: QAReport
  iterations?: number
  contentAnalysis?: ContentAnalysisResult
}

export type ProgressCallback = (message: string) => void

export async function generateDocumentWithMode(params: {
  prompt: string
  docType: DocType
  mode: AppMode
  styleConfig: any
  uploadedImages: UploadedImage[]
  priceItems: any[]
  parsedWebsiteData?: any
  onProgress?: ProgressCallback
}): Promise<GenerationResult> {
  const { prompt, docType, mode, styleConfig, uploadedImages, parsedWebsiteData, onProgress } = params

  const notify = (message: string) => {
    console.log(message)
    onProgress?.(message)
  }

  const modeNames = {
    free: '–±–µ—Å–ø–ª–∞—Ç–Ω–æ–º',
    advanced: '–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º',
    pro: 'PRO'
  }
  
  notify(`üöÄ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ ${modeNames[mode]} —Ä–µ–∂–∏–º–µ`)
  
  if (styleConfig && (styleConfig.name || styleConfig.primaryColor)) {
    const styleName = styleConfig.name || 'Custom'
    notify(`üé® –ü—Ä–∏–º–µ–Ω—è—é —Å—Ç–∏–ª—å: "${styleName}" (${styleConfig.primaryColor})`)
  }

  let iteration = 0
  let qaApproved = false
  let qaReport: QAReport | null = null
  let previousFeedback = ''
  
  let content = ''
  let html = ''
  let generatedImages: GeneratedImage[] = []
  let contentAnalysis: ContentAnalysisResult | null = null

  try {
    const config = MODE_CONFIG[mode]
    const textModel = config.models.text
    const useMultimodal = mode === 'advanced' && 'multimodal' in textModel && textModel.multimodal && uploadedImages.length > 0
    
    while (iteration < QA_CONFIG.maxIterations && !qaApproved) {
      iteration++
      
      if (iteration > 1) {
        notify(`üîÑ –£–ª—É—á—à–∞—é –¥–æ–∫—É–º–µ–Ω—Ç (–ø–æ–ø—ã—Ç–∫–∞ ${iteration}/${QA_CONFIG.maxIterations})`)
      }
      
      if (previousFeedback) {
        const shortFeedback = previousFeedback.length > 80 
          ? previousFeedback.substring(0, 80) + '...'
          : previousFeedback
        notify(`üìã –£—á–∏—Ç—ã–≤–∞—é –∑–∞–º–µ—á–∞–Ω–∏—è: ${shortFeedback}`)
      }

      if (useMultimodal) {
        notify(`üëÄ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à–∏ ${uploadedImages.length} ${uploadedImages.length === 1 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' : uploadedImages.length < 5 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' : '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}...`)
        const textPrompt = previousFeedback 
          ? `${prompt}\n\nIMPROVEMENT REQUIRED:\n${previousFeedback}` 
          : prompt
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4o –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ Advanced –∏ PRO —Ä–µ–∂–∏–º–∞—Ö
        const analysisModel = (mode === 'advanced' || mode === 'pro') 
          ? 'openai/gpt-4o'  // –õ—É—á—à–∏–π multimodal –∞–Ω–∞–ª–∏–∑
          : config.models.text.model
        console.log(`üîç Image analysis using model: ${analysisModel}`)
        content = await generateContentWithImages(
          textPrompt, 
          docType, 
          uploadedImages,
          analysisModel
        )
        notify(`‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã`)
      } else {
        notify(`üìù –ü–∏—à—É —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞...`)
        const model = mode === 'advanced' ? AGENT_MODELS.text : AGENT_MODELS.freeMode
        const textPrompt = previousFeedback 
          ? `${prompt}\n\nIMPROVEMENT REQUIRED:\n${previousFeedback}` 
          : prompt
        content = await generateContent(textPrompt, docType, model)
        notify(`‚úÖ –¢–µ–∫—Å—Ç –≥–æ—Ç–æ–≤`)
      }

      if (mode === 'advanced') {
        notify(`üé® –ü–ª–∞–Ω–∏—Ä—É—é AI –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞...`)
        contentAnalysis = await analyzeContentForImages(prompt, content, docType, previousFeedback)

        const imageCount = contentAnalysis.imagePrompts.length
        if (imageCount > 0) {
          notify(`üñºÔ∏è –°–æ–∑–¥–∞—é ${imageCount} ${imageCount === 1 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' : imageCount < 5 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' : '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}...`)
          
          // Advanced —Ä–µ–∂–∏–º: Flux Schnell (–±—ã—Å—Ç—Ä–∞—è, –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è)
          const fluxModel = 'black-forest-labs/flux-schnell'
          
          const images: GeneratedImage[] = []
          for (let i = 0; i < contentAnalysis.imagePrompts.length; i++) {
            const plan = contentAnalysis.imagePrompts[i]
            const shortPrompt = plan.prompt.length > 50 
              ? plan.prompt.substring(0, 50) + '...'
              : plan.prompt
            notify(`üé® –†–∏—Å—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ${i + 1}/${imageCount}: "${shortPrompt}"`)
            
            const singleImage = await generateImagesFromPlan([plan], previousFeedback, fluxModel)
            images.push(...singleImage)
          }
          generatedImages = images
          
          notify(`‚úÖ –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã!`)
        } else {
          notify(`‚ÑπÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞`)
        }

        const allImages = [
          ...generatedImages.map((img) => ({
            id: `ai-${img.slot}`,
            name: `AI Generated ${img.slot + 1}`,
            base64: img.dataUrl,
            type: 'image/png',
          })),
          ...uploadedImages,
        ]

        notify(`üèóÔ∏è –°–æ–±–∏—Ä–∞—é –¥–æ–∫—É–º–µ–Ω—Ç —Å –¥–∏–∑–∞–π–Ω–æ–º...`)
        html = await generateHTML(content, docType, styleConfig, allImages)
        notify(`‚úÖ –î–∏–∑–∞–π–Ω –ø—Ä–∏–º–µ–Ω—ë–Ω`)

        notify(`üîß –í—Å—Ç–∞–≤–ª—è—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω—É–∂–Ω—ã–µ –º–µ—Å—Ç–∞...`)
        html = replaceImagePlaceholders(html, generatedImages)
        
        notify(`üîç –ü—Ä–æ–≤–µ—Ä—è—é –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞...`)
        qaReport = await reviewDocument(prompt, content, generatedImages, html, docType, iteration)
        
        if (qaReport.approved && qaReport.score >= QA_CONFIG.approvalThreshold) {
          qaApproved = true
          notify(`üéâ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–π–¥–µ–Ω–∞! –û—Ü–µ–Ω–∫–∞: ${qaReport.score}/100`)
        } else {
          notify(`‚ö†Ô∏è –ù—É–∂–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è (–æ—Ü–µ–Ω–∫–∞ ${qaReport.score}/100)`)
          
          if (iteration < QA_CONFIG.maxIterations) {
            previousFeedback = buildFeedbackForAgents(qaReport)
          } else {
            notify(`‚è±Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ–ø—ã—Ç–æ–∫, –∏—Å–ø–æ–ª—å–∑—É—é —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç`)
          }
        }
      } else if (mode === 'free') {
        notify(`üèóÔ∏è –û—Ñ–æ—Ä–º–ª—è—é –¥–æ–∫—É–º–µ–Ω—Ç...`)
        html = await generateHTML(content, docType, styleConfig, uploadedImages)
        notify(`‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤`)
        qaApproved = true
      } else if (mode === 'pro') {
        notify(`üíé –ò—Å–ø–æ–ª—å–∑—É—é PRO —Ä–µ–∂–∏–º —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º`)
        
        if (uploadedImages.length > 0) {
          notify(`üëÄ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à–∏ ${uploadedImages.length} ${uploadedImages.length === 1 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' : uploadedImages.length < 5 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' : '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}...`)
          content = await generateContentWithImages(prompt, docType, uploadedImages, 'openai/gpt-4o')
          notify(`‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã`)
        } else {
          notify(`üìù –ü–∏—à—É —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞...`)
          content = await generateContent(prompt, docType, 'openai/gpt-4o')
          notify(`‚úÖ –¢–µ–∫—Å—Ç –≥–æ—Ç–æ–≤`)
        }

        // üîç –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å actionType='use-as-is'
        const imagesToUseAsIs = uploadedImages.filter(img => img.actionType === 'use-as-is')
        
        if (imagesToUseAsIs.length > 0) {
          // –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ –µ—Å—Ç—å
          notify(`‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é ${imagesToUseAsIs.length} –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö ${imagesToUseAsIs.length === 1 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' : '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}`)
          
          // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç GeneratedImage
          generatedImages = imagesToUseAsIs.map((img, index) => ({
            prompt: `Uploaded image: ${img.name}`,
            dataUrl: img.base64,
            slot: index
          }))
          
          notify(`‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!`)
        } else {
          // –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö "use-as-is" –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ AI
          notify(`üé® –ü–ª–∞–Ω–∏—Ä—É—é PRO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Flux 1.1 Pro)...`)
          contentAnalysis = await analyzeContentForImages(prompt, content, docType, previousFeedback, true)
          
          const imageCount = contentAnalysis.imagePrompts.length
          if (imageCount > 0) {
            notify(`üñºÔ∏è –°–æ–∑–¥–∞—é ${imageCount} PRO ${imageCount === 1 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' : imageCount < 5 ? '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è' : '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}...`)
            
            // PRO —Ä–µ–∂–∏–º: Flux 1.1 Pro (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –≤ 6 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ Flux Pro)
            const fluxProModel = 'black-forest-labs/flux-1.1-pro'
            
            const images: GeneratedImage[] = []
            for (let i = 0; i < contentAnalysis.imagePrompts.length; i++) {
              const plan = contentAnalysis.imagePrompts[i]
              const shortPrompt = plan.prompt.length > 50 
                ? plan.prompt.substring(0, 50) + '...'
                : plan.prompt
              notify(`üé® –°–æ–∑–¥–∞—é PRO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ${i + 1}/${imageCount}: "${shortPrompt}"`)
              
              const singleImage = await generateImagesFromPlan([plan], previousFeedback, fluxProModel)
              images.push(...singleImage)
            }
            generatedImages = images
            
            notify(`‚úÖ –í—Å–µ PRO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã!`)
          }
        }

        const allImages = [
          ...generatedImages.map((img) => ({
            id: `ai-dalle-${img.slot}`,
            name: `DALL-E 3 Generated ${img.slot + 1}`,
            base64: img.dataUrl,
            type: 'image/png',
          })),
          ...uploadedImages,
        ]

        notify(`üèóÔ∏è –°–æ–±–∏—Ä–∞—é PRO –¥–æ–∫—É–º–µ–Ω—Ç —Å –¥–∏–∑–∞–π–Ω–æ–º...`)
        // PRO —Ä–µ–∂–∏–º: –∏—Å–ø–æ–ª—å–∑—É–µ–º OpenRouter GPT-4o –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ OpenAI API (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–≤–æ—Ç—ã)
        html = await generateHTML(content, docType, styleConfig, uploadedImages, 'openai/gpt-4o')
        notify(`‚úÖ PRO –¥–∏–∑–∞–π–Ω –ø—Ä–∏–º–µ–Ω—ë–Ω`)

        notify(`üîß –í—Å—Ç–∞–≤–ª—è—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω—É–∂–Ω—ã–µ –º–µ—Å—Ç–∞...`)
        html = replaceImagePlaceholders(html, generatedImages)
        
        notify(`‚úÖ PRO –¥–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤!`)
        qaApproved = true
      }
    }

    notify(`‚ú® –î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!`)

    return {
      html,
      content,
      generatedImages,
      mode,
      qaReport: qaReport || undefined,
      iterations: iteration,
      contentAnalysis: contentAnalysis || undefined,
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'
    notify(`‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: ${errorMessage}`)
    console.error('‚ùå Orchestrator error:', error)
    throw error
  }
}

